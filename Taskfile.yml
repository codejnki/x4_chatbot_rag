# Taskfile for the X-Universe Data Extraction Pipeline
# Re-implementation of the original Makefile for better readability and maintenance.
version: '3'

vars:
  # Determine the Python executable based on the operating system.
  PYTHON: 'python'

  # --- File & Directory Definitions ---
  # Source Data
  ZIP_FILE: x4-foundations-wiki.zip

  # Prompts
  SUMMARIZER_PROMPT: prompts/document_summarizer_prompt.txt
  CHANGELOG_PROMPT: prompts/changelog_analyzer_prompt.txt

  # Output Directories
  SANITIZED_DIR: x4-foundations-wiki/hashed_pages
  MD_PAGES_DIR: x4-foundations-wiki/pages_md
  SUMMARIZED_PAGES_DIR: x4-foundations-wiki/pages_summarized
  VECTOR_STORE_DIR: faiss_index
  KEYWORDS_CACHE_DIR: .keyword_cache

  # Data Artifacts
  CHANGELOG_CHUNKS_FILE: x4_changelog_chunks.json
  WIKI_CHUNKS_FILE: x4_wiki_chunks.json
  ALL_CHUNKS_FILE: x4_all_chunks.json
  KEYWORDS_FILE: x4_keywords.json
  REFINED_KEYWORDS_FILE: x4_keywords_refined.json

  # Marker file to track step completion, replacing .unzipped and .processed
  MARKER_FILE: .task_complete

tasks:
  default:
    desc: Lists all available tasks, similar to the original 'help' target.
    cmds:
      - task --list-all
    silent: true

  # ---------------------------------------------------------------------------
  # --- Main Targets
  # ---------------------------------------------------------------------------

  run:
    desc: (Default) Builds all data and starts the FastAPI server.
    deps: [all]
    cmds:
      - '{{.PYTHON}} main.py'

  all:
    desc: Builds all data artifacts required by the application.
    deps: [9-keywords-refined]

  # ---------------------------------------------------------------------------
  # --- Data Processing Pipeline (in order)
  # ---------------------------------------------------------------------------

  '1-data':
    desc: 'Step 1: Unzips and sanitizes the raw wiki HTML data.'
    sources:
      - '{{.ZIP_FILE}}'
      - 00_unzip_data.py
    generates:
      - '{{.SANITIZED_DIR}}/{{.MARKER_FILE}}'
    cmds:
      - '{{.PYTHON}} 00_unzip_data.py'
      - touch {{.SANITIZED_DIR}}/{{.MARKER_FILE}}

  '2-markdown':
    desc: 'Step 2: Converts HTML files to Markdown in parallel.'
    deps: ['1-data']
    sources:
      - '{{.SANITIZED_DIR}}/{{.MARKER_FILE}}'
      - 01a_html_to_md.py
      - 01c_get_files_to_process.py
    generates:
      - '{{.MD_PAGES_DIR}}/{{.MARKER_FILE}}'
    cmds:
      - '{{.PYTHON}} 01c_get_files_to_process.py {{.SANITIZED_DIR}} {{.MD_PAGES_DIR}} .html .md | xargs -P 8 -I {} {{.PYTHON}} 01a_html_to_md.py {}'
      - touch {{.MD_PAGES_DIR}}/{{.MARKER_FILE}}

  '3-markdown-summaries':
    desc: 'Step 3: Enriches markdown files with LLM-generated summaries.'
    deps: ['2-markdown']
    sources:
      - '{{.MD_PAGES_DIR}}/{{.MARKER_FILE}}'
      - 01b_summarize_md.py
      - 01c_get_files_to_process.py
      - '{{.SUMMARIZER_PROMPT}}'
    generates:
      - '{{.SUMMARIZED_PAGES_DIR}}/{{.MARKER_FILE}}'
    cmds:
      - '{{.PYTHON}} 01c_get_files_to_process.py {{.MD_PAGES_DIR}} {{.SUMMARIZED_PAGES_DIR}} .md .md | xargs -P 2 -I {} {{.PYTHON}} 01b_summarize_md.py {}'
      - touch {{.SUMMARIZED_PAGES_DIR}}/{{.MARKER_FILE}}

  '4-changelog-chunks':
    desc: 'Step 4: Extracts and structures data from changelog files.'
    deps: ['2-markdown']
    sources:
      - '{{.MD_PAGES_DIR}}/{{.MARKER_FILE}}'
      - 01d_process_changelogs.py
      - '{{.CHANGELOG_PROMPT}}'
    generates:
      - '{{.CHANGELOG_CHUNKS_FILE}}'
    cmds:
      - '{{.PYTHON}} 01d_process_changelogs.py'

  '5-wiki-chunks':
    desc: 'Step 5: Breaks down summarized markdown files into smaller chunks.'
    deps: ['3-markdown-summaries']
    sources:
      - '{{.SUMMARIZED_PAGES_DIR}}/{{.MARKER_FILE}}'
      - 02_chunk_corpus.py
    generates:
      - '{{.WIKI_CHUNKS_FILE}}'
    cmds:
      - '{{.PYTHON}} 02_chunk_corpus.py'

  '6-merged-chunks':
    desc: 'Step 6: Combines the wiki and changelog chunks into a single file.'
    deps: ['5-wiki-chunks', '4-changelog-chunks']
    sources:
      - '{{.WIKI_CHUNKS_FILE}}'
      - '{{.CHANGELOG_CHUNKS_FILE}}'
      - 02b_merge_chunks.py
    generates:
      - '{{.ALL_CHUNKS_FILE}}'
    cmds:
      - '{{.PYTHON}} 02b_merge_chunks.py'

  '7-vector-store':
    desc: 'Step 7: Creates a FAISS vector store from the merged chunks.'
    deps: ['6-merged-chunks']
    sources:
      - '{{.ALL_CHUNKS_FILE}}'
      - 03_build_vector_store.py
    generates:
      - '{{.VECTOR_STORE_DIR}}/{{.MARKER_FILE}}'
    cmds:
      - '{{.PYTHON}} 03_build_vector_store.py'
      - touch {{.VECTOR_STORE_DIR}}/{{.MARKER_FILE}}

  '8-keywords':
    desc: 'Step 8: Generates keywords from the data chunks.'
    deps: ['7-vector-store']
    sources:
      - '{{.VECTOR_STORE_DIR}}/{{.MARKER_FILE}}'
      - 04_generate_keywords.py
    generates:
      - '{{.KEYWORDS_FILE}}'
    cmds:
      - '{{.PYTHON}} 04_generate_keywords.py'

  '9-keywords-refined':
    desc: 'Step 9: Filters the keyword list to create a domain-specific list.'
    deps: ['8-keywords']
    sources:
      - '{{.KEYWORDS_FILE}}'
      - 05_refine_keywords.py
    generates:
      - '{{.REFINED_KEYWORDS_FILE}}'
    cmds:
      - '{{.PYTHON}} 05_refine_keywords.py'

  # ---------------------------------------------------------------------------
  # --- Clean Tasks
  # ---------------------------------------------------------------------------
  clean:
    desc: Removes all generated data, caches, and artifacts.
    deps:
      - clean:data
      - clean:markdown
      - clean:markdown-summaries
      - clean:chunks
      - clean:vector-store
      - clean:keywords

  clean:data:
    desc: Deletes the unzipped and sanitized HTML data.
    cmds:
      - rm -rf {{.SANITIZED_DIR}}

  clean:markdown:
    desc: Deletes the generated markdown pages.
    cmds:
      - rm -rf {{.MD_PAGES_DIR}}

  clean:markdown-summaries:
    desc: Deletes the summarized markdown pages.
    cmds:
      - rm -rf {{.SUMMARIZED_PAGES_DIR}}

  clean:chunks:
    desc: Deletes all generated chunk files.
    cmds:
      - rm -f {{.CHANGELOG_CHUNKS_FILE}} {{.WIKI_CHUNKS_FILE}} {{.ALL_CHUNKS_FILE}}

  clean:vector-store:
    desc: Deletes the FAISS vector store.
    cmds:
      - rm -rf {{.VECTOR_STORE_DIR}}

  clean:keywords:
    desc: Deletes all keyword files and the cache.
    cmds:
      - rm -rf {{.KEYWORDS_CACHE_DIR}}
      - rm -f {{.KEYWORDS_FILE}} {{.REFINED_KEYWORDS_FILE}}
